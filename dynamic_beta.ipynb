{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEIR model with time-varying $\\beta$\n",
    "\n",
    "**References**\n",
    "\n",
    "[Epidemic Modeling 101: Or why your CoVID-19 exponential fits are wrong](https://medium.com/data-for-science/epidemic-modeling-101-or-why-your-covid19-exponential-fits-are-wrong-97aa50c55f8)\n",
    "\n",
    "[Epidemic Modeling 102: All CoVID-19 models are wrong, but some are useful](https://medium.com/data-for-science/epidemic-modeling-102-all-covid-19-models-are-wrong-but-some-are-useful-c81202cc6ee9)\n",
    "\n",
    "[Compartmental models in epidemiology](https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology)\n",
    "\n",
    "## Background\n",
    "\n",
    "We want to explore the effect of interventions in an epidemic. We use a standard epidemiological SEIR model (see references above), and model the effect of interventions as reducing the infection coefficient $\\beta$.\n",
    "\n",
    "The equations are\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial S_t}{\\partial t} &= -\\beta S_t \\frac{I_t}{N} \\\\\n",
    "\\frac{\\partial E_t}{\\partial t} &= \\beta S_t \\frac{I_t}{N} - \\alpha E_t\\\\\n",
    "\\frac{\\partial I_t}{\\partial t} &= \\alpha E_t - \\mu I_t \\\\\n",
    "\\frac{\\partial R_t}{\\partial t} &= \\mu I_t\n",
    "\\end{align}$$\n",
    "\n",
    "where\n",
    "$$\\begin{align}\n",
    "\\alpha^{-1} &= \\text{average incubation period} \\\\\n",
    "\\beta &= \\text{rate of infection} \\\\\n",
    "\\mu &= \\text{rate of recovery}\n",
    "\\end{align}$$\n",
    "\n",
    "Now \n",
    "$$R_0 = \\frac{\\beta}{\\mu}$$\n",
    "\n",
    "is the basic reproduction number. A basic result is that the number of people unaffected by the disease $S_\\infty$ can be determined from the relation\n",
    "\n",
    "$$S_\\infty =e^{-R_0 (1-S_\\infty)}$$\n",
    "\n",
    "A guess for the value of $R_0$ for COVID-19 is 2.5. We will model the effect of measures like physical distancing as reducing $\\beta$ and hence $R_0$ over time. We will therefore regard them as time-dependent quantities, $R_t$ and $\\beta_t$.\n",
    "\n",
    "Although in some ways it is only the ratio $\\beta / \\mu$ that matters, the magnitudes of $\\beta$ and $\\mu$ affect how quickly the epidemic unfolds.\n",
    "\n",
    "To incorporate these ideas into the numerical integration, we will specify two times (step numbers), $t_1$ and $t_2$, in addition to the total number of steps $t_f - 1$. Then $\\beta_t$ has the value $\\beta_i$ for $t\\le t_1$, $\\beta_f$ for $t >= t_2$ and ramps linearly in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import date\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import fsolve, least_squares\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r0_to_infected(r0):\n",
    "    \"\"\"Compute limit value of population infected\"\"\"\n",
    "    def func(Sinf, r0):\n",
    "        return Sinf - np.exp(-r0 * (1 - Sinf))\n",
    "    \n",
    "    return 1 - fsolve(func, 0.5, args=r0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_new_cases(cases_cum):\n",
    "    \"\"\"Calculate new cases based on cumulative cases. New cases are the total cases in the previous week.\"\"\"\n",
    "    # Do some funny business to impute weekly sums at beginning of time series\n",
    "    cases_ext = backcast(np.log(cases_cum[:7] + 1e-7), 7)\n",
    "    cases_ext = np.exp(cases_ext)\n",
    "\n",
    "    cases_new = np.zeros_like(cases_cum)\n",
    "    cases_new[:7] = cases_cum[:7] - cases_ext\n",
    "    cases_new[7:] = cases_cum[7:] - cases_cum[:-7]\n",
    "    \n",
    "    return cases_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backcast(y, n):\n",
    "    \"\"\"Use linear regression to extrapolate values to before start of time series\"\"\"\n",
    "    X = np.arange(len(y)).reshape(-1, 1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    X_predict = np.arange(-n, 0).reshape(-1, 1)\n",
    "    return model.predict(X_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of modeled data\n",
    "This is a model with fixed parameters just to see what the outputs look like and how they look in the log-log visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equations to be integrated\n",
    "t0 = 0\n",
    "t1 = 60  # 20\n",
    "t2 = t1 + 20  # 60\n",
    "t3 = 180  # 365\n",
    "r1 = 2.0  # 2.5\n",
    "r2 = 0.9 # 0.5\n",
    "mu = 1 / 7  # 1 / 14\n",
    "beta1 = r1 * mu\n",
    "beta2 = r2 * mu\n",
    "alpha = 1 / 7\n",
    "N = 5.1e6  # 1e6\n",
    "E0 = N * 0.01  # 1\n",
    "I0 = 0  # 1\n",
    "S0 = N - E0 - I0\n",
    "R0 = 0\n",
    "\n",
    "def beta(t):\n",
    "    if t <= t1:\n",
    "        return beta1\n",
    "    if t <= t2:\n",
    "        return beta2 - (t2 - t) * (beta2 - beta1) / (t2 - t1)\n",
    "    return beta2\n",
    "\n",
    "\n",
    "def fun(t, y):\n",
    "    dy_dt = np.zeros_like(y)\n",
    "    S, E, I, R = y\n",
    "    dS_dt = -beta(t) * S * I / N\n",
    "    dE_dt = beta(t) * S * I / N - alpha * E\n",
    "    dI_dt = alpha * E - mu * I\n",
    "    dR_dt = mu * I\n",
    "    return dS_dt, dE_dt, dI_dt, dR_dt\n",
    "    \n",
    "#     dy_dt[0] = -beta(t) * y[0] * y[1] / N\n",
    "#     dy_dt[1] = beta(t) * y[0] * y[1] / N - mu * y[1]\n",
    "#     dy_dt[2] = mu * y[1]\n",
    "#     return dy_dt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the equations (numerically)\n",
    "bunch = solve_ivp(fun, t_span=(t0, t3), y0=(S0, E0, I0, R0), t_eval=np.arange(t3 + 1))\n",
    "S, E, I, R = bunch.y\n",
    "t = bunch.t\n",
    "Imax = np.max(I) / N\n",
    "Iarg = np.argmax(I)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(f'Maximum infections: {Imax:.1%} at {Iarg} days')\n",
    "ax.plot(t, S / N, label='Susceptible')\n",
    "ax.plot(t, E / N, label='Exposed')\n",
    "ax.plot(t, I / N, label='Infected')\n",
    "ax.plot(t, R / N, label='Recovered')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_cum = E + I + R\n",
    "plt.plot(t, cases_cum / N, label='Cumulative cases')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_new = calc_new_cases(cases_cum)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cases_cum, cases_new)\n",
    "ax.set_ylim(bottom=1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit reported case counts to this model\n",
    "The model fits these parameters:\n",
    "- $\\beta_1, \\beta_2$: the initial and final values of the rate of infection\n",
    "- $t_1, t_2$: the start and end time of the linear $\\beta$ ramp\n",
    "- $\\mu$: rate of recovery\n",
    "- $I_0$: the number of people infected\n",
    "- $E_0$: the number of people exposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "#!!! TO DO Fetch this data dynamically\n",
    "region = 'New Zealand'\n",
    "if region == 'South Korea':\n",
    "    N = 50e6\n",
    "    y_train = np.array([1,1,2,2,3,4,4,4,4,11,12,15,15,16,19,23,24,24,25,27,28,28,28,28,28,29,30,31,31,104,204,433,602,833,977,\n",
    "                  1261,1766,2337,3150,3736,4335,5186,5621,6088,6593,7041,7314,7478,7513,7755,7869,7979,8086,8162,8236,\n",
    "                  8320,8413,8565,8652,8799,8961,8961,9037,9137,9241,9332,9478,9583,9661,9786,9887,9976,10062,10156,\n",
    "                  10237,10284,10331,10384,10423,10450])[28:]\n",
    "elif region == 'Alberta':\n",
    "    N = 4.3e6\n",
    "    y_train = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,2,4,14,\n",
    "                        14,19,23,29,39,56,74,97,119,146,195,226,259,301,358,419,486,542,621,661,690,754,871,968,1075,\n",
    "                        1181,1250,1348,1373,1423,1451,1500,1569])[43:]\n",
    "elif region == 'British Columbia':\n",
    "    N = 5.1e6\n",
    "    y_train = np.array([0,0,0,0,0,0,1,1,1,1,1,1,1,1,2,4,4,4,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,7,7,7,7,7,8,8,8,12,13,21,21,\n",
    "                        27,27,32,39,46,53,64,73,73,103,186,231,271,348,424,472,539,617,659,725,792,884,900,970,1013,\n",
    "                        1066,1121,1174,1203,1229,1266,1291,1336,1370,1410,1445,1470,1490,1517,1561,1575,1618,1647,\n",
    "                        1676,1699,1724])[-30:]\n",
    "elif region == 'Germany':\n",
    "    N = 83e6\n",
    "    y_train = np.array([0,0,0,0,0,1,4,4,4,5,8,10,12,12,12,12,13,13,14,14,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,27,46,48,\n",
    "                        79,130,159,196,262,482,670,799,1040,1176,1457,1908,2078,3675,4585,5795,7272,9257,12327,15320,19848,\n",
    "                        22213,24873,29056,32986,37323,43938,50871,57695,62095,66885,71808,77872,84794,91159,96092,100123,\n",
    "                        103374,107663,113296,118181,122171])[30:]\n",
    "elif region == 'Italy':\n",
    "    N = 60.36e6\n",
    "    y_train = np.array([0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,20,62,155,229,322,453,655,888,1128,\n",
    "                        1694,2036,2502,3089,3858,4636,5883,7375,9172,10149,12462,12462,17660,21157,24747,27980,31506,\n",
    "                        35713,41035,47021,53578,59138,63927,69176,74386,80589,86498,92472,97689,101739,105792,110574,\n",
    "                        115242,119827,124632,128948,132547,135586,139422,143626,147577,152271,156363,159516,162488,\n",
    "                        165155,168941,172434,175925])[30:]\n",
    "elif region == 'Quebec':\n",
    "    N = 8.537e6\n",
    "    y_train = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,3,3,3,3,7,\n",
    "                        7,9,17,17,21,32,50,74,94,121,139,181,219,628,1013,1339,1629,2021,2498,2840,3430,4162,4611,5518,\n",
    "                        6101,6997,7944,8580,9340,10031,10912,11677,12292,12846])[50:]\n",
    "elif region == 'Sweden':\n",
    "    N = 10.3e6\n",
    "    y_train = np.array([0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,7,7,12,14,15,21,35,94,\n",
    "                        101,161,203,248,355,500,599,814,961,1022,1103,1190,1279,1439,1639,1763,1934,2046,2286,2526,\n",
    "                        2840,3069,3447,3700,4028,4435,4947,5568,6131,6443,6830,7206,7693,8419,9141,9685,10151,10483])[50:]\n",
    "elif region == 'US':\n",
    "    N = 328.2e6\n",
    "    y_train = np.array([1,1,2,2,5,5,5,5,5,7,8,8,11,11,11,11,11,11,11,11,12,12,13,13,13,13,13,13,13,13,15,15,15,51,51,\n",
    "                        57,58,60,68,74,98,118,149,217,262,402,518,583,959,1281,1663,2179,2727,3499,4632,6421,7783,13747,\n",
    "                        19273,25600,33276,43847,53740,65778,83836,101657,121465,140909,161831,188172,213372,243762,\n",
    "                        275586,308853,337072,366667,396223,429052,461437,496535,526396])[50:]\n",
    "elif region == 'Washington State':\n",
    "    N = 7.615e6\n",
    "    y_train = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,5,5,5,5,7,10,17,23,32,47,75,86,\n",
    "                        110,141,179,279,338,419,511,609,675,794,908,1026,1228,1404,1655,1844,2101,2469,2585,3208,3770,\n",
    "                        4311,4896,5179,5292,5588,6585,6966,7498,7984,8384,8682,9097,9608,9887,10224,10411])[40:]\n",
    "elif region == 'New Zealand':\n",
    "    N = 4.886e6\n",
    "    y_train = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,3,3,4,\n",
    "                        5,5,5,5,5,5,5,6,8,8,12,20,28,39,52,102,102,155,205,283,368,451,514,589,647,708,797,868,950,\n",
    "                        1039,1106,1160,1210,1239,1283,1312,1330,1349,1366,1386,1401,1409,1422,1431,1440,1445])[55:]\n",
    "else:\n",
    "    raise RuntimeError(f'Unknown region: {region}')\n",
    "t_train = np.arange(len(y_train))\n",
    "print(f'cumulative cases: min: {np.min(y_train):,}, max: {np.max(y_train):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, with initial values\n",
    "t1 = 10  # 10\n",
    "t2 = t1 + 20  # 30\n",
    "mu = 1 / 7  # 1 / 14\n",
    "beta1 = 2.0 * mu\n",
    "beta2 = 0.9 * mu\n",
    "alpha = 1 / 3\n",
    "I0 = np.min(y_train) // 2\n",
    "E0 = I0\n",
    "# x0 =    np.array([t1, t2,   mu,     beta1,    beta2,      E0,      I0])\n",
    "x0 =    np.array([t1, t2,   mu,       beta1,       beta2, alpha,      E0,      I0])\n",
    "lower = np.array([ 0,  0, 1e-4, 0.5 * beta1, 0.5 * beta2,     0,       0,       0])\n",
    "upper = np.array([30, 60,  100, 2.0 * beta1, 2.0 * beta2,    10, N * 0.1, N * 0.1])\n",
    "print(', '.join([f'{xx:.2f}' for xx in x0]))\n",
    "print(np.all(x0 >= lower))\n",
    "print(np.all(x0 <= upper))\n",
    "print(np.all(upper > lower))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, t, y):\n",
    "    \"\"\"\n",
    "    Function to be used for optimization\n",
    "    \n",
    "    Arguments:\n",
    "        x     parameters to be fit\n",
    "        t     independent variable\n",
    "        y     observed data\n",
    "    \"\"\"\n",
    "    t1, t2, mu, beta1, beta2, alpha, E0, I0 = x\n",
    "    t0 = 0\n",
    "    t3 = len(t) - 1\n",
    "\n",
    "    \n",
    "    def beta(t):\n",
    "        if t <= t1:\n",
    "            return beta1\n",
    "        if t <= t2:\n",
    "            return beta2 - (t2 - t) * (beta2 - beta1) / (t2 - t1)\n",
    "        return beta2\n",
    "\n",
    "\n",
    "    def fun(t, y):\n",
    "        \"\"\"Differential equations to be integrated\"\"\"\n",
    "        S, E, I, R = y\n",
    "        dS_dt = -beta(t) * S * I / N\n",
    "        dE_dt = beta(t) * S * I / N - alpha * E\n",
    "        dI_dt = alpha * E - mu * I\n",
    "        dR_dt = mu * I\n",
    "        \n",
    "        return dS_dt, dE_dt, dI_dt, dR_dt\n",
    "\n",
    "    S, E, I, R = solve_ivp(fun, t_span=(t0, t3), y0=(N-E0-I0, E0, I0, 0), t_eval=np.arange(t3 + 1)).y\n",
    "#     print(f'{t0}, {t3}: {S.shape}, {I.shape}, {R.shape}')\n",
    "\n",
    "    return E + I + R - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lsq = least_squares(fit, x0, method='trf', bounds=(lower, upper), args=(t_train, y_train))\n",
    "t1, t2, mu, beta1, beta2, alpha, E0, I0 = res_lsq.x\n",
    "\n",
    "names = [\"t1\", \"t2\", \"mu\", \"beta1\", \"beta2\", \"alpha\", \"E0\", \"I0\"]\n",
    "ddict = { 'parameter': [], 'initial': [], 'fit': []}\n",
    "for i, name in enumerate(names):\n",
    "    ddict['parameter'].append(name)\n",
    "    ddict['initial'].append(x0[i])\n",
    "    ddict['fit'].append(res_lsq.x[i])\n",
    "df = pd.DataFrame.from_dict(ddict)\n",
    "df.set_index('parameter', inplace=True)\n",
    "display(df)\n",
    "\n",
    "print(f'R initial: {beta1 / mu:.1f}, R fit: {beta2 / mu:.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = fit(res_lsq.x, t_train, y_train) + y_train\n",
    "\n",
    "print(f'Final value of cumulative cases reported: {y_train[-1]:7,.0f}')\n",
    "print(f'Final value of cumulative cases fit:      {y_fit[-1]:7,.0f}')\n",
    "\n",
    "plt.plot(t_train, y_fit, zorder=2, label='fit')\n",
    "plt.plot(t_train, y_train, 'o', zorder=1, label='measured')\n",
    "plt.title(region)\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('cumulative cases')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_cum_rep = y_train\n",
    "cases_new_rep = calc_new_cases(cases_cum_rep)\n",
    "cases_cum_fit = y_fit\n",
    "cases_new_fit = calc_new_cases(cases_cum_fit)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'{region}')\n",
    "ax.plot(cases_cum_fit, cases_new_fit, zorder=2, label='fit')\n",
    "ax.plot(cases_cum_rep, cases_new_rep, 'o', zorder=1, label='reported')  # , color='#55a868'\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('cumulative cases')\n",
    "plt.ylabel('new cases per week')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolate\n",
    "n_days = 200\n",
    "t_train_e = np.arange(n_days)\n",
    "y_train_e = np.zeros(n_days)\n",
    "y_fit_e = fit(res_lsq.x, t_train_e, y_train_e) + y_train_e\n",
    "\n",
    "plt.plot(t_train_e, y_fit_e, zorder=2, label='fit')\n",
    "plt.plot(t_train, y_train, 'o', zorder=1, label='reported')\n",
    "plt.title(f'{region} - extrapolated')\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('cumulative cases')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_cum_fit_e = y_fit_e\n",
    "cases_new_fit_e = calc_new_cases(cases_cum_fit_e)\n",
    "cases_cum = y_train\n",
    "cases_new = calc_new_cases(cases_cum)\n",
    "\n",
    "final_cases = cases_cum_fit_e[-1]\n",
    "R1 = beta1 / mu\n",
    "R2 = beta2 / mu\n",
    "subtitle = f'total cases: {N * r0_to_infected(R1):,.0f} => {final_cases:,.0f}, R: {R1:.1f} => {R2:.1f}'\n",
    "datestamp = date.today().strftime('%Y%m%d')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(f'{region} - extrapolated\\n{subtitle}')\n",
    "ax.plot(cases_cum_fit_e, cases_new_fit_e, zorder=2, label='fit extrapolated')\n",
    "ax.plot(cases_cum, cases_new, 'o', zorder=1, label='reported')\n",
    "plt.xlabel('cumulative cases')\n",
    "plt.ylabel('new cases per week')\n",
    "ax.set_ylim(bottom=1, top=1e6)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "# fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(f'{region.lower().replace(\" \", \"_\")}_extrapolated_{datestamp}.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
